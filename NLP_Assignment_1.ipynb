{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "290dAk7vfbv7",
        "outputId": "b13cbd78-3119-4d0b-8108-c5336b434fb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import WhitespaceTokenizer, WordPunctTokenizer, TreebankWordTokenizer, MWETokenizer\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.stem import PorterStemmer, SnowballStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "B9vV4Rh5gLzJ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W49H4Y33gUMC",
        "outputId": "93776b42-8fbc-48e1-ab95-507a2e60e4a0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resume_text = \"\"\"\n",
        "John Snow\n",
        "Email: john.snow@example.com | Phone: +1 123-456-7890\n",
        "Objective: To secure a challenging role in AI development.\n",
        "Education: B.Sc. in Computer Science, XYZ University, 2020\n",
        "Skills: Python, NLP, Machine Learning, TensorFlow, Keras\n",
        "Experience:\n",
        "- AI Engineer at ABC Corp (2021â€“Present): Developed chatbots and recommendation systems.\n",
        "- Intern at DEF Inc. (2020): Assisted in data preprocessing for AI models.\n",
        "\"\"\"\n",
        "skills_list = {\"python\", \"nlp\", \"machine learning\", \"tensorflow\", \"keras\", \"ai\"}\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_and_filter(tokens, stop_words, lemmatizer):\n",
        "    return [\n",
        "        lemmatizer.lemmatize(token.lower())\n",
        "        for token in tokens\n",
        "        if token.lower() not in stop_words\n",
        "    ]\n",
        "\n",
        "\n",
        "tokenizer = WhitespaceTokenizer()\n",
        "resume_tokens = preprocess_and_filter(tokenizer.tokenize(resume_text), stop_words, lemmatizer)\n",
        "job_tokens = preprocess_and_filter(tokenizer.tokenize(job_description), stop_words, lemmatizer)\n",
        "\n",
        "matching_skills = skills_list.intersection(set(resume_tokens), set(job_tokens))\n",
        "print(\"Matching Skills:\", matching_skills)"
      ],
      "metadata": {
        "id": "ZcfqvcFZgdOv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ed21270-4a81-4d8a-be39-9007c95c52ba"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matching Skills: {'ai'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "def remove_stop_words(tokens):\n",
        "    return [word for word in tokens if word not in stop_words]"
      ],
      "metadata": {
        "id": "kCYxFQcDle2w"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_text = re.sub(r'\\s+', ' ', resume_text)\n",
        "cleaned_text = re.sub(r'[^\\w\\s@.-]', '', cleaned_text)\n",
        "print(cleaned_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rK9ziUqNggtg",
        "outputId": "d48d812d-e4fa-42f8-a760-fec70e1ce0e4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " John Snow Email john.snow@example.com  Phone 1 123-456-7890 Objective To secure a challenging role in AI development. Education B.Sc. in Computer Science XYZ University 2020 Skills Python NLP Machine Learning TensorFlow Keras Experience - AI Engineer at ABC Corp 2021Present Developed chatbots and recommendation systems. - Intern at DEF Inc. 2020 Assisted in data preprocessing for AI models. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "whitespace_tokenizer = WhitespaceTokenizer()\n",
        "tokens_whitespace = whitespace_tokenizer.tokenize(cleaned_text)\n",
        "print(\"Whitespace Tokens:\", tokens_whitespace)\n",
        "\n",
        "word_punct_tokenizer = WordPunctTokenizer()\n",
        "tokens_punct = word_punct_tokenizer.tokenize(cleaned_text)\n",
        "print(\"Punctuation-Based Tokens:\", tokens_punct)\n",
        "\n",
        "treebank_tokenizer = TreebankWordTokenizer()\n",
        "tokens_treebank = treebank_tokenizer.tokenize(cleaned_text)\n",
        "print(\"Treebank Tokens:\", tokens_treebank)\n",
        "\n",
        "tweet_tokenizer = TweetTokenizer()\n",
        "tokens_tweet = tweet_tokenizer.tokenize(cleaned_text)\n",
        "print(\"Tweet Tokens:\", tokens_tweet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3W1PSmKg204",
        "outputId": "e44031eb-0c58-4772-b680-ebd82d16775a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Whitespace Tokens: ['John', 'Snow', 'Email', 'john.snow@example.com', 'Phone', '1', '123-456-7890', 'Objective', 'To', 'secure', 'a', 'challenging', 'role', 'in', 'AI', 'development.', 'Education', 'B.Sc.', 'in', 'Computer', 'Science', 'XYZ', 'University', '2020', 'Skills', 'Python', 'NLP', 'Machine', 'Learning', 'TensorFlow', 'Keras', 'Experience', '-', 'AI', 'Engineer', 'at', 'ABC', 'Corp', '2021Present', 'Developed', 'chatbots', 'and', 'recommendation', 'systems.', '-', 'Intern', 'at', 'DEF', 'Inc.', '2020', 'Assisted', 'in', 'data', 'preprocessing', 'for', 'AI', 'models.']\n",
            "Punctuation-Based Tokens: ['John', 'Snow', 'Email', 'john', '.', 'snow', '@', 'example', '.', 'com', 'Phone', '1', '123', '-', '456', '-', '7890', 'Objective', 'To', 'secure', 'a', 'challenging', 'role', 'in', 'AI', 'development', '.', 'Education', 'B', '.', 'Sc', '.', 'in', 'Computer', 'Science', 'XYZ', 'University', '2020', 'Skills', 'Python', 'NLP', 'Machine', 'Learning', 'TensorFlow', 'Keras', 'Experience', '-', 'AI', 'Engineer', 'at', 'ABC', 'Corp', '2021Present', 'Developed', 'chatbots', 'and', 'recommendation', 'systems', '.', '-', 'Intern', 'at', 'DEF', 'Inc', '.', '2020', 'Assisted', 'in', 'data', 'preprocessing', 'for', 'AI', 'models', '.']\n",
            "Treebank Tokens: ['John', 'Snow', 'Email', 'john.snow', '@', 'example.com', 'Phone', '1', '123-456-7890', 'Objective', 'To', 'secure', 'a', 'challenging', 'role', 'in', 'AI', 'development.', 'Education', 'B.Sc.', 'in', 'Computer', 'Science', 'XYZ', 'University', '2020', 'Skills', 'Python', 'NLP', 'Machine', 'Learning', 'TensorFlow', 'Keras', 'Experience', '-', 'AI', 'Engineer', 'at', 'ABC', 'Corp', '2021Present', 'Developed', 'chatbots', 'and', 'recommendation', 'systems.', '-', 'Intern', 'at', 'DEF', 'Inc.', '2020', 'Assisted', 'in', 'data', 'preprocessing', 'for', 'AI', 'models', '.']\n",
            "Tweet Tokens: ['John', 'Snow', 'Email', 'john.snow@example.com', 'Phone', '1 123-456-7890', 'Objective', 'To', 'secure', 'a', 'challenging', 'role', 'in', 'AI', 'development', '.', 'Education', 'B.Sc', '.', 'in', 'Computer', 'Science', 'XYZ', 'University', '2020', 'Skills', 'Python', 'NLP', 'Machine', 'Learning', 'TensorFlow', 'Keras', 'Experience', '-', 'AI', 'Engineer', 'at', 'ABC', 'Corp', '2021Present', 'Developed', 'chatbots', 'and', 'recommendation', 'systems', '.', '-', 'Intern', 'at', 'DEF', 'Inc', '.', '2020', 'Assisted', 'in', 'data', 'preprocessing', 'for', 'AI', 'models', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "porter_stemmer = PorterStemmer()\n",
        "stemmed_words_porter = [porter_stemmer.stem(word) for word in tokens_whitespace]\n",
        "print(\"Porter Stemmed Words:\", stemmed_words_porter)\n",
        "\n",
        "snowball_stemmer = SnowballStemmer(\"english\")\n",
        "stemmed_words_snowball = [snowball_stemmer.stem(word) for word in tokens_whitespace]\n",
        "print(\"Snowball Stemmed Words:\", stemmed_words_snowball)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuPFBNUJg-dB",
        "outputId": "472b00a9-8533-48b8-f7af-e09b46ea7bf8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Porter Stemmed Words: ['john', 'snow', 'email', 'john.snow@example.com', 'phone', '1', '123-456-7890', 'object', 'to', 'secur', 'a', 'challeng', 'role', 'in', 'ai', 'development.', 'educ', 'b.sc.', 'in', 'comput', 'scienc', 'xyz', 'univers', '2020', 'skill', 'python', 'nlp', 'machin', 'learn', 'tensorflow', 'kera', 'experi', '-', 'ai', 'engin', 'at', 'abc', 'corp', '2021present', 'develop', 'chatbot', 'and', 'recommend', 'systems.', '-', 'intern', 'at', 'def', 'inc.', '2020', 'assist', 'in', 'data', 'preprocess', 'for', 'ai', 'models.']\n",
            "Snowball Stemmed Words: ['john', 'snow', 'email', 'john.snow@example.com', 'phone', '1', '123-456-7890', 'object', 'to', 'secur', 'a', 'challeng', 'role', 'in', 'ai', 'development.', 'educ', 'b.sc.', 'in', 'comput', 'scienc', 'xyz', 'univers', '2020', 'skill', 'python', 'nlp', 'machin', 'learn', 'tensorflow', 'kera', 'experi', '-', 'ai', 'engin', 'at', 'abc', 'corp', '2021present', 'develop', 'chatbot', 'and', 'recommend', 'systems.', '-', 'intern', 'at', 'def', 'inc.', '2020', 'assist', 'in', 'data', 'preprocess', 'for', 'ai', 'models.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_with_pos(word):\n",
        "    return lemmatizer.lemmatize(word, pos=wordnet.VERB)\n",
        "\n",
        "lemmatized_words = [lemmatize_with_pos(word) for word in tokens_whitespace]\n",
        "print(\"Lemmatized Words:\", lemmatized_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "varFWsLohBYB",
        "outputId": "b64b356b-d095-4edd-f9a9-a12f96488cbb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemmatized Words: ['John', 'Snow', 'Email', 'john.snow@example.com', 'Phone', '1', '123-456-7890', 'Objective', 'To', 'secure', 'a', 'challenge', 'role', 'in', 'AI', 'development.', 'Education', 'B.Sc.', 'in', 'Computer', 'Science', 'XYZ', 'University', '2020', 'Skills', 'Python', 'NLP', 'Machine', 'Learning', 'TensorFlow', 'Keras', 'Experience', '-', 'AI', 'Engineer', 'at', 'ABC', 'Corp', '2021Present', 'Developed', 'chatbots', 'and', 'recommendation', 'systems.', '-', 'Intern', 'at', 'DEF', 'Inc.', '2020', 'Assisted', 'in', 'data', 'preprocessing', 'for', 'AI', 'models.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "email = re.search(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}', cleaned_text)\n",
        "print(\"Email:\", email.group() if email else \"Not found\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vz9KKKYLhFPg",
        "outputId": "c32e34ba-543f-4a55-e966-740cdbaa0317"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Email: john.snow@example.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "phone = re.search(r'\\+?\\d[\\d -]{8,}\\d', cleaned_text)\n",
        "print(\"Phone:\", phone.group() if phone else \"Not found\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGXmOVTPhHKY",
        "outputId": "fd8371bb-7bf9-4cf6-f6e0-dab0fb1fe587"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Phone: 1 123-456-7890\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "skills = re.findall(r'\\b(Python|NLP|Machine Learning|TensorFlow|Keras)\\b', cleaned_text, re.IGNORECASE)\n",
        "print(\"Skills:\", skills)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGCJB9slhLya",
        "outputId": "4f94d895-bc69-4f89-c739-c8dc2aed51b7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skills: ['Python', 'NLP', 'Machine Learning', 'TensorFlow', 'Keras']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "education = re.search(r'(B\\.Sc\\.|M\\.Sc\\.|Ph\\.D\\.) in [\\w\\s]+', cleaned_text)\n",
        "print(\"Education:\", education.group() if education else \"Not found\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHbcQI46hOGx",
        "outputId": "d03f0762-f957-4a51-abf7-6469171624e8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Education: B.Sc. in Computer Science XYZ University 2020 Skills Python NLP Machine Learning TensorFlow Keras Experience \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "job_description = \"\"\"\n",
        "Looking for an AI Engineer skilled in Python, NLP, and Machine Learning.\n",
        "\"\"\"\n",
        "\n",
        "job_tokens = [lemmatizer.lemmatize(word.lower()) for word in WhitespaceTokenizer().tokenize(job_description)]\n",
        "job_tokens_filtered = remove_stop_words(job_tokens)\n",
        "\n",
        "resume_tokens = [lemmatizer.lemmatize(word.lower()) for word in tokens_whitespace]\n",
        "resume_tokens_filtered = remove_stop_words(resume_tokens)\n",
        "\n",
        "common_skills = set(job_tokens_filtered).intersection(resume_tokens_filtered)\n",
        "print(\"Matching Skills:\", common_skills)\n",
        "\n",
        "tokenizer = WhitespaceTokenizer()\n",
        "resume_tokens = preprocess_and_filter(tokenizer.tokenize(resume_text), stop_words, lemmatizer)\n",
        "job_tokens = preprocess_and_filter(tokenizer.tokenize(job_description), stop_words, lemmatizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "To1i9dYmhTI5",
        "outputId": "ab6024ae-291e-491b-f2d5-8ba5376cff9d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matching Skills: {'machine', 'ai', 'engineer'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_resume(resume_text, job_description):\n",
        "    cleaned_text = re.sub(r'\\s+', ' ', resume_text)\n",
        "    cleaned_text = re.sub(r'[^\\w\\s@.-]', '', cleaned_text)\n",
        "\n",
        "    tokens = WhitespaceTokenizer().tokenize(cleaned_text)\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    normalized_tokens = [lemmatizer.lemmatize(word.lower()) for word in tokens]\n",
        "\n",
        "    email = re.search(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}', cleaned_text)\n",
        "    phone = re.search(r'\\+?\\d[\\d -]{8,}\\d', cleaned_text)\n",
        "    skills = re.findall(r'\\b(Python|NLP|Machine Learning|TensorFlow|Keras)\\b', cleaned_text, re.IGNORECASE)\n",
        "\n",
        "    job_tokens = [lemmatizer.lemmatize(word.lower()) for word in WhitespaceTokenizer().tokenize(job_description)]\n",
        "    matching_skills = set(normalized_tokens).intersection(job_tokens)\n",
        "\n",
        "    return {\n",
        "        \"email\": email.group() if email else \"Not found\",\n",
        "        \"phone\": phone.group() if phone else \"Not found\",\n",
        "        \"skills\": skills,\n",
        "        \"matching_skills\": list(matching_skills),\n",
        "    }\n",
        "\n",
        "job_description = \"Looking for AI Engineer skilled in Python, NLP, and Machine Learning.\"\n",
        "result = analyze_resume(resume_text, job_description)\n",
        "print(\"Analysis Result:\", result)"
      ],
      "metadata": {
        "id": "pV4M13ZsheIH",
        "outputId": "3ca51ec1-824f-4f69-b140-05c0213f8442",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analysis Result: {'email': 'john.snow@example.com', 'phone': '1 123-456-7890', 'skills': ['Python', 'NLP', 'Machine Learning', 'TensorFlow', 'Keras'], 'matching_skills': ['for', 'in', 'ai', 'engineer', 'and', 'machine']}\n"
          ]
        }
      ]
    }
  ]
}